## Architecture Alignment with Roadmap

The backend’s overall architecture and tech stack align well with the planned **v2.1/v3 design**. Notable points of alignment:

- **Node.js + Express stack:** The project is structured as a Node/Express application, as intended[GitHub](https://github.com/nutri-org/nutri-gpt-assistant/blob/e5bb499f52e6ab9179aa8aa5b305e52572740b42/docs/replit_backend_plan_v_2_1.md#L23-L31). The folder layout (server/routes, server/lib, etc.) matches the plan’s scaffold for v2.1[GitHub](https://github.com/nutri-org/nutri-gpt-assistant/blob/e5bb499f52e6ab9179aa8aa5b305e52572740b42/docs/replit_backend_plan_v_2_1.md#L92-L101)[GitHub](https://github.com/nutri-org/nutri-gpt-assistant/blob/e5bb499f52e6ab9179aa8aa5b305e52572740b42/docs/replit_backend_plan_v_2_1.md#L104-L111). Key components like `openaiClient.js` for OpenAI integration, `buildPrompt.js` for mode-specific prompt construction, and `guardRails.js` for post-checks are all present and used exactly as designed[GitHub](https://github.com/nutri-org/nutri-gpt-assistant/blob/e5bb499f52e6ab9179aa8aa5b305e52572740b42/server/lib/openaiClient.js#L40-L48)[GitHub](https://github.com/nutri-org/nutri-gpt-assistant/blob/e5bb499f52e6ab9179aa8aa5b305e52572740b42/server/lib/openaiClient.js#L52-L61)[GitHub](https://github.com/nutri-org/nutri-gpt-assistant/blob/e5bb499f52e6ab9179aa8aa5b305e52572740b42/server/lib/guardRails.js#L10-L18).
- **Dual chat modes & JSON schema:** The strict vs. creative mode behavior is correctly implemented. The code uses an OpenAI function call with the defined `MealPlanSchema` when `mode === "meal_plan_strict"` to enforce structured JSON output[GitHub](https://github.com/nutri-org/nutri-gpt-assistant/blob/e5bb499f52e6ab9179aa8aa5b305e52572740b42/server/lib/buildPrompt.js#L43-L51)[GitHub](https://github.com/nutri-org/nutri-gpt-assistant/blob/e5bb499f52e6ab9179aa8aa5b305e52572740b42/server/lib/buildPrompt.js#L52-L60). For `goal_motivation` mode it provides a more conversational system prompt and higher temperature[GitHub](https://github.com/nutri-org/nutri-gpt-assistant/blob/e5bb499f52e6ab9179aa8aa5b305e52572740b42/server/lib/buildPrompt.js#L7-L15)[GitHub](https://github.com/nutri-org/nutri-gpt-assistant/blob/e5bb499f52e6ab9179aa8aa5b305e52572740b42/server/lib/buildPrompt.js#L16-L24). This matches the spec which required mode-aware output discipline (structured JSON vs. free-form)[GitHub](https://github.com/nutri-org/nutri-gpt-assistant/blob/e5bb499f52e6ab9179aa8aa5b305e52572740b42/docs/replit_backend_plan_v_2_1.md#L14-L22)[GitHub](https://github.com/nutri-org/nutri-gpt-assistant/blob/e5bb499f52e6ab9179aa8aa5b305e52572740b42/docs/replit_backend_plan_v_2_1.md#L70-L78). The function-calling approach ensures the meal plan JSON adheres to schema, fulfilling the “valid MealPlanSchema” contract.
- **Supabase integration:** The plan called for using Supabase (Postgres) both for persistent data (user quota, settings, datasets) and file storage[GitHub](https://github.com/nutri-org/nutri-gpt-assistant/blob/e5bb499f52e6ab9179aa8aa5b305e52572740b42/attached_assets/Pasted--1-Create-docs-backend-plan-v3-md-supersedes-v2-1-cat-docs-backend-plan-v3-md-EOF-Nutr-1753812672052_1753812672053.txt#L18-L22). The implementation indeed uses Supabase’s JS client (`server/lib/supabase`) to perform DB operations and uploads to storage. For example, the quota middleware queries the `users` table and invokes a Postgres RPC via Supabase JS SDK[GitHub](https://github.com/nutri-org/nutri-gpt-assistant/blob/e5bb499f52e6ab9179aa8aa5b305e52572740b42/middleware/quota.js#L9-L17)[GitHub](https://github.com/nutri-org/nutri-gpt-assistant/blob/e5bb499f52e6ab9179aa8aa5b305e52572740b42/middleware/quota.js#L19-L23), and the dataset route uses `supabase.storage.from('datasets').upload(...)` to store files[GitHub](https://github.com/nutri-org/nutri-gpt-assistant/blob/e5bb499f52e6ab9179aa8aa5b305e52572740b42/server/routes/datasets.js#L26-L34). The DB schema migration aligns perfectly with the roadmap: the `users` table is extended with `plan` and `remaining_credits`, and new tables for `datasets` and `assistant_settings` are created[GitHub](https://github.com/nutri-org/nutri-gpt-assistant/blob/e5bb499f52e6ab9179aa8aa5b305e52572740b42/db/migrations/20250730_r1.sql#L2-L10)[GitHub](https://github.com/nutri-org/nutri-gpt-assistant/blob/e5bb499f52e6ab9179aa8aa5b305e52572740b42/db/migrations/20250730_r1.sql#L6-L14)[GitHub](https://github.com/nutri-org/nutri-gpt-assistant/blob/e5bb499f52e6ab9179aa8aa5b305e52572740b42/db/migrations/20250730_r1.sql#L15-L23), exactly as listed in the v3 plan[GitHub](https://github.com/nutri-org/nutri-gpt-assistant/blob/e5bb499f52e6ab9179aa8aa5b305e52572740b42/attached_assets/Pasted--1-Create-docs-backend-plan-v3-md-supersedes-v2-1-cat-docs-backend-plan-v3-md-EOF-Nutr-1753812672052_1753812672053.txt#L18-L22). This shows strong alignment between the intended data model and the actual implementation.
- **Deployment and configuration:** The codebase includes a `/api/healthz` endpoint for uptime checks[GitHub](https://github.com/nutri-org/nutri-gpt-assistant/blob/e5bb499f52e6ab9179aa8aa5b305e52572740b42/server/routes/health.js#L5-L12), consistent with using it for health monitoring. Environment variables like `JWT_SECRET` and `STRIPE_SIGNING_SECRET` are used as expected for security[GitHub](https://github.com/nutri-org/nutri-gpt-assistant/blob/e5bb499f52e6ab9179aa8aa5b305e52572740b42/.env.example#L2-L7). The presence of a `SIGTERM` and `SIGINT` handler in `index.js` for graceful shutdown[GitHub](https://github.com/nutri-org/nutri-gpt-assistant/blob/e5bb499f52e6ab9179aa8aa5b305e52572740b42/index.js#L9-L17)[GitHub](https://github.com/nutri-org/nutri-gpt-assistant/blob/e5bb499f52e6ab9179aa8aa5b305e52572740b42/index.js#L18-L25) is a good practice, ensuring alignment with a production environment (likely Replit autoscaling or similar). The plan’s mention of p99 ≤ 3s @ 25 RPM and autoscale is more about performance; this isn’t directly verifiable in code, but the non-blocking design (async/await and external API calls) is consistent with achieving those targets.

**Areas of misalignment or deviation:**

- **Admin authorization model:** The plan explicitly noted some endpoints as “admin only” (dataset upload, assistant prompt updates)[GitHub](https://github.com/nutri-org/nutri-gpt-assistant/blob/e5bb499f52e6ab9179aa8aa5b305e52572740b42/attached_assets/Pasted--1-Create-docs-backend-plan-v3-md-supersedes-v2-1-cat-docs-backend-plan-v3-md-EOF-Nutr-1753812672052_1753812672053.txt#L24-L32). The code, however, does not implement an admin role or any differentiation beyond the `plan` field. Currently any authenticated user can hit those endpoints. This is a significant deviation in terms of security assumptions. If the intention is to restrict those actions to privileged users, the implementation will need an update (e.g. a flag in JWT or a user role field).
- **Token-based auth vs. Supabase Auth:** The system uses a custom JWT secret and manual auth middleware, whereas using Supabase Auth (which issues its own JWTs with a built-in `authenticated` role) might have been expected. The approach is fine, but it means the app is somewhat “rolling its own” auth. The token is expected to carry `id` and `plan`, which implies the token must be custom-issued by the app or configured via Supabase JWT claims. Currently, there’s no endpoint to log in or obtain such a token in this repo. This could be an omission (perhaps handled outside the repo), but it’s a gap in alignment – the plan assumed an existing bearer token mechanism and possibly a single shared token for Replit in v2.1[GitHub](https://github.com/nutri-org/nutri-gpt-assistant/blob/e5bb499f52e6ab9179aa8aa5b305e52572740b42/docs/replit_backend_plan_v_2_1.md#L27-L35)[GitHub](https://github.com/nutri-org/nutri-gpt-assistant/blob/e5bb499f52e6ab9179aa8aa5b305e52572740b42/docs/replit_backend_plan_v_2_1.md#L43-L51), whereas v3 moves to user-specific JWTs. The code is in between: it expects user-specific JWTs but doesn’t show how they’re created.
- **Lack of rate-limit 429 response:** The plan’s error contract mentioned HTTP 429 for rate limiting (perhaps if Supabase triggers or policies enforced it)[GitHub](https://github.com/nutri-org/nutri-gpt-assistant/blob/e5bb499f52e6ab9179aa8aa5b305e52572740b42/docs/replit_backend_plan_v_2_1.md#L82-L89). In the implemented code, hitting quota returns 403 `QUOTA_EXCEEDED` (not 429)[GitHub](https://github.com/nutri-org/nutri-gpt-assistant/blob/e5bb499f52e6ab9179aa8aa5b305e52572740b42/middleware/quota.js#L14-L18), and there’s no other rate limit logic. This is a minor mismatch in semantics (403 vs 429) and suggests no explicit rate-throttling besides the credit system.
- **Test coverage vs. milestones:** The roadmap milestones R1–R5 correspond to implementing auth, quota, webhook, upload, settings with tests[GitHub](https://github.com/nutri-org/nutri-gpt-assistant/blob/e5bb499f52e6ab9179aa8aa5b305e52572740b42/attached_assets/Pasted--1-Create-docs-backend-plan-v3-md-supersedes-v2-1-cat-docs-backend-plan-v3-md-EOF-Nutr-1753812672052_1753812672053.txt#L34-L42). Most of these have tests, but as noted, the upload route lacks a dedicated test, which means R4 (“jest upload.test.js green”[GitHub](https://github.com/nutri-org/nutri-gpt-assistant/blob/e5bb499f52e6ab9179aa8aa5b305e52572740b42/attached_assets/Pasted--1-Create-docs-backend-plan-v3-md-supersedes-v2-1-cat-docs-backend-plan-v3-md-EOF-Nutr-1753812672052_1753812672053.txt#L38-L41)) may not have been fully realized. It’s possible this was an oversight or the test exists in a different form not easily found. All other milestones (auth, chat mode, quota, settings) have passing tests, aligning with the plan’s done criteria of “all endpoints pass unit tests”[GitHub](https://github.com/nutri-org/nutri-gpt-assistant/blob/e5bb499f52e6ab9179aa8aa5b305e52572740b42/attached_assets/Pasted--1-Create-docs-backend-plan-v3-md-supersedes-v2-1-cat-docs-backend-plan-v3-md-EOF-Nutr-1753812672052_1753812672053.txt#L44-L48).

In summary, the backend’s design is largely consistent with the planned architecture. The core features (multi-mode chat, credit-based usage tiers, Stripe integration, persistent settings) are either in place or in progress. The primary misalignments are in **access control** (admin vs. user) and some missing auxiliary pieces (token issuance, file size limits, etc.), which we detail in the next section.

## Gaps and Missing Functionality

Below is a list of functionality gaps or deviations, with an assessment of their impact:

- **Missing Admin Privileges** (**High Severity**): Endpoints intended for admin use are not actually restricted. For example, `/api/datasets/upload` and `/api/assistant/settings` updates can be invoked by any authenticated user (no check on user’s plan or role)[GitHub](https://github.com/nutri-org/nutri-gpt-assistant/blob/e5bb499f52e6ab9179aa8aa5b305e52572740b42/server/routes/datasets.js#L14-L21)[GitHub](https://github.com/nutri-org/nutri-gpt-assistant/blob/e5bb499f52e6ab9179aa8aa5b305e52572740b42/server/routes/settings.js#L43-L51). This is a security issue if certain features (like uploading reference datasets or changing prompt templates) should be limited to internal or paid users. Implementing role-based auth (e.g. an `isAdmin` flag or treating `plan: 'unlimited'` as admin) is needed to fill this gap.
- **No User Authentication Flow** (**High Severity**): The system expects JWTs but provides no API to log in or obtain them. There’s no `/login` or Supabase auth integration shown. Without integration, new users cannot easily get a valid `JWT_SECRET`-signed token to use the API. If Supabase Auth is being used behind the scenes, the code would need to use the Supabase JWT secret and include user claims. This gap could block any new user from actually using the system unless tokens are manually issued, so it’s critical to address (either by documenting that Supabase handles auth or by adding endpoints for login/signup).
- **Stripe Customer Linking & Purchase Flow** (**Medium Severity**): While the webhook updates user records, the flow to create a Stripe Checkout Session and record the `stripe_customer` ID for a user is missing. Without it, the webhook can’t find which user to upgrade (unless the Stripe customer ID was manually added to the user row). This is a functional gap – implementing an endpoint like `POST /api/billing/checkout` to initiate a payment (returning a Stripe session URL or ID) and creating/linking the Stripe customer to the user would complete the billing integration. Also, if the pricing model involves recurring subscriptions, handling subscription renewal events (e.g. `invoice.paid` events to re-up credits each billing cycle) might be needed down the line – currently such events are ignored[GitHub](https://github.com/nutri-org/nutri-gpt-assistant/blob/e5bb499f52e6ab9179aa8aa5b305e52572740b42/tests/billing.test.js#L101-L108).
- **File Upload Size & Safety Checks** (**Medium Severity**): The dataset upload endpoint does not enforce the 10 MB file size limit from the plan, nor any type validation. This means a malicious or careless user could attempt to upload a huge file (dozens of MBs in base64 JSON), potentially exhausting API memory or storage. The absence of `multipart/form-data` handling (it expects base64 in JSON) also means the entire file is read into memory via `Buffer.from(...)`[GitHub](https://github.com/nutri-org/nutri-gpt-assistant/blob/e5bb499f52e6ab9179aa8aa5b305e52572740b42/server/routes/datasets.js#L26-L34), which can crash the process for very large files. This needs a safeguard (check `fileData` length and reject >10 MB with 413 or 400 error). Additionally, there’s no scanning for content (which might be okay for now, but admins might want to ensure no personally identifiable or dangerous content is uploaded).
- **Content Moderation & Abuse Prevention** (**Medium Severity**): Beyond allergen/medication conflicts, the assistant has **no content filter**. Users could potentially prompt it with inappropriate or harmful requests outside nutritional scope. Production-grade AI apps usually integrate content moderation – e.g., OpenAI’s free moderation endpoint can detect and flag hateful, self-harm, or violent content[skimai.com](https://skimai.com/10-best-practices-for-managing-user-generated-content-with-openais-api/#:~\:text=AI%20skimai,The%20endpoint). Nutri-GPT currently lacks such filters. Likewise, there’s no mechanism to detect prompt injection or misuse (the model instructions are somewhat fixed per mode, but a crafty user could still try to manipulate it). Prompt abuse or off-label use isn’t checked, representing a potential risk (the assistant might give medical advice or other disallowed content without checks). Addressing this would involve adding a middleware to run inputs (and possibly outputs) through a moderation API or a custom filter list.
- **Rate Limiting & Request Throttling** (**Low/Medium Severity**): The credit quota system provides a basic **usage limit**, but there is no short-term rate limiting (e.g. requests per minute). A user with credits could still spam the API with rapid requests. Industry practice is to enforce rate limits per minute or per IP to prevent abuse and manage cost spikes[zuplo.com](https://zuplo.com/blog/2023/10/11/rate-limiting-openai-requests#:~\:text=Rate%20limiting%20is%20a%20great,AI%20models%20in%20your%20API). Implementing such limits (e.g. using an in-memory counter or using an API gateway rule) would harden the service. Also, the app returns `403` for exhausted credits – using `429 Too Many Requests` in such cases (or when adding rate throttle) would be more standard. This is a moderate concern; at low scale it may not matter, but as usage grows, not having any burst control could impact stability.
- **Logging and Monitoring** (**Low Severity**): Aside from console logs and the health check, there’s no dedicated logging of user activity or error monitoring service integrated. For example, each chat request and response is not saved anywhere. Lack of audit logs means troubleshooting or analyzing usage (e.g. to see why a response was malformed or to gather feedback) is harder. Moreover, critical errors are only printed to console – in a production deployment, one would typically pipe these to an external monitor (like Sentry or CloudWatch). The current approach meets minimal requirements but leaves a visibility gap. Introducing structured logging (with user ID, timestamps, etc.) and an error alerting system would be valuable as the platform matures.
- **Test Coverage Gaps** (**Low Severity**): As noted, the dataset upload route has no test, and the auth middleware isn’t directly tested for edge cases (e.g. invalid token structure). While not immediately user-facing, these untested parts could hide bugs. For instance, if Supabase returns an error during file upload, does the code handle it gracefully? (It does check `uploadError` and `dbError` and returns 500 with details[GitHub](https://github.com/nutri-org/nutri-gpt-assistant/blob/e5bb499f52e6ab9179aa8aa5b305e52572740b42/server/routes/datasets.js#L34-L42)[GitHub](https://github.com/nutri-org/nutri-gpt-assistant/blob/e5bb499f52e6ab9179aa8aa5b305e52572740b42/server/routes/datasets.js#L52-L60), which is good). Writing tests for file upload (perhaps with a small base64 string) and for auth required vs optional routes would shore up confidence and catch regressions in these areas.
- **Minor Implementation Quirks** (**Low Severity**): There are a few minor issues in code that are not breaking anything now but are worth noting. For example, duplicate route mounting (`server/app.js` vs `server/server.js`) – it appears `server/server.js` supersedes `app.js` by including all routes and middleware[GitHub](https://github.com/nutri-org/nutri-gpt-assistant/blob/e5bb499f52e6ab9179aa8aa5b305e52572740b42/server/server.js#L21-L28), and `index.js` uses `server/server`[GitHub](https://github.com/nutri-org/nutri-gpt-assistant/blob/e5bb499f52e6ab9179aa8aa5b305e52572740b42/index.js#L2-L7), so `app.js` might be a leftover. This could confuse new contributors. Also, the Stripe webhook sets `remaining_credits: null` for unlimited plan[GitHub](https://github.com/nutri-org/nutri-gpt-assistant/blob/e5bb499f52e6ab9179aa8aa5b305e52572740b42/server/routes/billing.js#L19-L27); this relies on code treating `null` as effectively infinite. The quota middleware doesn’t actually handle a null value explicitly – it fetches `remaining_credits`[GitHub](https://github.com/nutri-org/nutri-gpt-assistant/blob/e5bb499f52e6ab9179aa8aa5b305e52572740b42/middleware/quota.js#L9-L17) and checks `< 1`[GitHub](https://github.com/nutri-org/nutri-gpt-assistant/blob/e5bb499f52e6ab9179aa8aa5b305e52572740b42/middleware/quota.js#L14-L18). If `remaining_credits` is `null`, the `< 1` check might throw or be truthy in unexpected ways. In practice, it likely comes through as `data: { remaining_credits: null }` and that comparison would fail (probably causing an error or always allowing?). This edge case could be handled more cleanly (e.g. set unlimited users’ credits to a very large number or make the query condition `remaining_credits IS NOT NULL`). These issues are not immediate show-stoppers but should be cleaned up to avoid bugs as the codebase grows.
